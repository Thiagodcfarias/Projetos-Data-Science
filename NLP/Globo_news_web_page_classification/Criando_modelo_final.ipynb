{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisando os dados dos sites da globo usando bag of words\n",
    "\n",
    "* No notebook anterior, foram removidos as stop words e palavras que enviesavam o modelo\n",
    "\n",
    "Agora, o objetivo é aplicar algoritmos para generalizar o modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('C:\\\\Users\\\\samsung\\\\Desktop\\\\df_sites_globo2_stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'titulo', 'conteudo', 'url_origem', 'texto_processado'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método to_csv converte strings sem valor ('') em np.nan, verificar se apareceu alguma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[587]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['texto_processado'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   '"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.conteudo[587] # estava lá desde o início :( Melhor remover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([587], axis=0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1499, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando alguns modelos de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vetorizador = CountVectorizer(max_features = 50)\n",
    "bag_of_words = vetorizador.fit_transform(df['texto_processado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg_log = LogisticRegression()\n",
    "\n",
    "from sklearn import svm\n",
    "svm_default = svm.SVC()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "random_forest = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(bag_of_words, df.url_origem, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7757575757575758\n",
      "0.7494949494949495\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "reg_log.fit(x_train,y_train)\n",
    "print(reg_log.score(x_test,y_test))\n",
    "\n",
    "svm_default.fit(x_train,y_train)\n",
    "print(svm_default.score(x_test,y_test))\n",
    "\n",
    "random_forest.fit(x_train,y_train)\n",
    "print(random_forest.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poderíamos otimizar os modelos nessa abordagem. No entanto, temos poucos dados e nosso modelo não será muito confiável<br>\n",
    "Portanto, vamos usar uma abordagem usando TFIDF e validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=50)\n",
    "modelo_tfidf = tfidf.fit_transform(df.texto_processado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression reached 0.75 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(reg_log, modelo_tfidf, df.url_origem, cv=10)\n",
    "print(\"Logistic regression reached %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM reached 0.72 accuracy with a standard deviation of 0.03\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm_default, modelo_tfidf, df.url_origem, cv=10)\n",
    "print(\"SVM reached %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_forest reached 0.72 accuracy with a standard deviation of 0.03\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svm_default, modelo_tfidf, df.url_origem, cv=10)\n",
    "print(\"random_forest reached %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repetindo para 100 palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression reached 0.82 accuracy with a standard deviation of 0.03\n",
      "SVM reached 0.78 accuracy with a standard deviation of 0.03\n",
      "Random forest reached 0.81 accuracy with a standard deviation of 0.03\n"
     ]
    }
   ],
   "source": [
    "tfidf_100 = TfidfVectorizer(max_features=100)\n",
    "modelo_tfidf_100 = tfidf_100.fit_transform(df.texto_processado)\n",
    "\n",
    "scores = cross_val_score(reg_log, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(\"Logistic regression reached %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(svm_default, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(\"SVM reached %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "scores = cross_val_score(random_forest, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(\"Random forest reached %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refinamento dos hiperparâmetros\n",
    "\n",
    "Em todos os testes, a regressão logistica esteve melhor que os demais. Além disso, é bem mais performática para se treinar. <br>Portanto, vamos refinar os hiperparâmetros apenas desse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "liblinear = LogisticRegression(solver = 'liblinear')\n",
    "newtoncg = LogisticRegression(solver = 'newton-cg')\n",
    "sag = LogisticRegression(solver = 'sag')\n",
    "saga = LogisticRegression(solver = 'saga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8185413870246085 0.02511594920391652\n",
      "0.8192080536912751 0.02540953778806545\n",
      "0.8192080536912751 0.02540953778806545\n",
      "0.8185413870246085 0.02511594920391652\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(liblinear, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())\n",
    "\n",
    "scores = cross_val_score(newtoncg, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())\n",
    "\n",
    "scores = cross_val_score(sag, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())\n",
    "\n",
    "scores = cross_val_score(saga, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "liblinear = LogisticRegression(solver = 'liblinear',max_iter = 500)\n",
    "newtoncg = LogisticRegression(solver = 'newton-cg',max_iter = 500)\n",
    "sag = LogisticRegression(solver = 'sag',max_iter = 500)\n",
    "saga = LogisticRegression(solver = 'saga',max_iter = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8185413870246085 0.02511594920391652\n",
      "0.8192080536912751 0.02540953778806545\n",
      "0.8192080536912751 0.02540953778806545\n",
      "0.8185413870246085 0.02511594920391652\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(liblinear, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())\n",
    "\n",
    "scores = cross_val_score(newtoncg, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())\n",
    "\n",
    "scores = cross_val_score(sag, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())\n",
    "\n",
    "scores = cross_val_score(saga, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(scores.mean(), scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression reached 0.82 accuracy with a standard deviation of 0.03\n"
     ]
    }
   ],
   "source": [
    "reg_log = LogisticRegression(max_iter = 500)\n",
    "scores = cross_val_score(reg_log, modelo_tfidf_100, df.url_origem, cv=10)\n",
    "print(\"Logistic regression reached %0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mudar os parâmetros da regressão não tiveram efeitos significativos, portanto vamos ficar com o modelo padrão\n",
    "\n",
    "Resultado final: 82% de acc com sd de 0.03 :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
